{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluation_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNi37jAYgbnXuVDSasDJc3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sihan827/2021_Winter_PE/blob/main/evaluation_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JPv0LFhObUT"
      },
      "source": [
        "# Evaluation Metric 분석\r\n",
        "\r\n",
        "# 아래 변수들은 모델 성능을 평가하기 위한 클래스 AverageMeter의 인스턴스\r\n",
        "# 순서대로 top-1, top-5, 손실 관련 평가 지표를 저장하는 데 사용\r\n",
        "top1_meter = AverageMeter()\r\n",
        "top5_meter = AverageMeter()\r\n",
        "loss_meter = AverageMeter()\r\n",
        "\r\n",
        "# 테스트 함수\r\n",
        "def test(loader):\r\n",
        "    # 모델을 eval 모드로 바꾸어 모델을 테스트하는 동안 dropout 등으로 인해\r\n",
        "    # 신경망의 일부를 사용하지 못하게 하는 것을 방지\r\n",
        "    model.eval()\r\n",
        "    # 기본적으로 torch는 autograd=True로 명시된 파라미터들이 기록에 남아서 \r\n",
        "    # 나중에 역전파 알고리즘 수행시 이 기록을 참고하여 미분을 하여 수행함\r\n",
        "    # 테스트 시에는 각 파라미터들을 최적화하지 않으므로 미분값을 계산할 필요가 없고\r\n",
        "    # 이는 torch.no_grad를 통해 파라미터들이 기록에 남지 않아서 메모리를 아낄 수 있음\r\n",
        "    with torch.no_grad():\r\n",
        "        # 학습과정과 유사하게 enumerate함수와 반복문을 통해 \r\n",
        "        # 한 배치의 인덱스, 데이터, 라벨을 불러옴\r\n",
        "        for step, (X, y) in enumerate(loader):\r\n",
        "            # cuda 사용설정 \r\n",
        "            X, y = X.cuda(), y.cuda()\r\n",
        "            # 한 배치의 크기를 N에 저장\r\n",
        "            N = X.shape[0]\r\n",
        "\r\n",
        "            # 모델을 통한 예측값 계산\r\n",
        "            outs = model(X)\r\n",
        "            # 지정한 손실함수를 통해 예측값과 실제 라벨값 사이의 손실값 계산\r\n",
        "            loss = criterion(outs, y)\r\n",
        "            # 미리 지정된 accuracy 함수를 통해 현재 배치에 대하여\r\n",
        "            # 예측값과 실제 라벨 사이 top-1, top-5 정답률을 계산\r\n",
        "            prec1, prec3 = accuracy(outs, y, topk=(1,5))\r\n",
        "            # 처음에 선언한 AverageMeter의 각 인스턴스 안의 지표들을 업데이트\r\n",
        "            # (총합, 평균, 개수)\r\n",
        "            top1_meter.update(prec1.item(), N)\r\n",
        "            top5_meter.update(prec3.item(), N)\r\n",
        "            loss_meter.update(loss.item(), N)\r\n",
        "\r\n",
        "    # 각 인스턴스에 저장된 평균값을 가져옴\r\n",
        "    # top-1, top-5에서 평균값은 정답률을 의미하고\r\n",
        "    # loss에서 평균값은 말그대로 해당 배치 데이터들의 평균값을 의미 \r\n",
        "    top1_avg = top1_meter.get_avg()\r\n",
        "    top5_avg = top5_meter.get_avg()\r\n",
        "    loss_avg = loss_meter.get_avg()\r\n",
        "\r\n",
        "    # 한 배치에 대하여 각 평가 파라미터들을 계산했으므로\r\n",
        "    # 해당 클래스의 reset 함수로 모든 값을 초기화\r\n",
        "    for avg in [top1_meter, top5_meter, loss_meter]:\r\n",
        "        avg.reset()\r\n",
        "\r\n",
        "    # 평가지표 출력\r\n",
        "    print('[Test] Loss: {loss:.4f}, Top1: {top1: .4f}, Top5: {top5: .4f}'.format(\r\n",
        "        loss=loss_avg,\r\n",
        "        top1=top1_avg,\r\n",
        "        top5=top5_avg\r\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}